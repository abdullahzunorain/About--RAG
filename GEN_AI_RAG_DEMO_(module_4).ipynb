{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahzunorain/About--RAG/blob/main/GEN_AI_RAG_DEMO_(module_4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intall library in order to use the api for the model\n"
      ],
      "metadata": {
        "id": "lhuFQYKYGNM_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxzIBRnkFfr-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install groq\n",
        "!pip install sentence_transformers\n",
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas faiss-cpu torch transformers\n"
      ],
      "metadata": {
        "id": "YRWLIAkrl8FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get an api from the groq\n",
        "\n",
        "Link To get Api Key: https://console.groq.com/keys"
      ],
      "metadata": {
        "id": "wlCdrEiyGc_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# api_key=\"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\""
      ],
      "metadata": {
        "id": "xa3v4LpMGpPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_TOKEN = userdata.get('GROQ_API_TOKEN')"
      ],
      "metadata": {
        "id": "pRSbfnHCcg0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose model of your choice\n",
        "\n",
        "Link for getting Models: https://console.groq.com/docs"
      ],
      "metadata": {
        "id": "r3navS0rIjfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_TOKEN,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"what is ai\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "GVXP_nmPIwDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find a Dataset on which u want to make a RAG\n",
        "\n",
        "Link for the dataset: https://www.kaggle.com/datasets/utkarshx27/movies-dataset"
      ],
      "metadata": {
        "id": "VLuhqTDUJu8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"utkarshx27/movies-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "YtJVUStMc06H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "# !pip install faiss\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "id": "aQCWbPfud7pj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "oDV4SyHmg5Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "WS4Qq613TTzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import os"
      ],
      "metadata": {
        "id": "W74NM0YAbNPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"utkarshx27/movies-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Find the CSV file within the downloaded directory\n",
        "# Assuming there's only one CSV file in the directory\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_file = os.path.join(path, filename)\n",
        "        break  # Stop searching after finding the first CSV file\n",
        "else:\n",
        "    raise FileNotFoundError(\"No CSV file found in the downloaded dataset directory.\")\n",
        "\n",
        "# Load CSV data\n",
        "df = pd.read_csv(csv_file) # Assuming the file is a standard CSV\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0AXcexIFeWNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "I0H1Nlkyjs0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "_Omcgm5SG8Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 'overview' as the source for documents\n",
        "documents = df['overview'].tolist()\n",
        "\n",
        "# Clean the documents list to ensure all entries are strings\n",
        "documents = [str(doc) if pd.notnull(doc) else \"\" for doc in documents]\n",
        "\n",
        "# Initialize the SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for each document\n",
        "doc_embeddings = model.encode(documents, show_progress_bar=True)\n",
        "\n",
        "# Convert to NumPy array (FAISS requires float32)\n",
        "embedding_matrix = np.array(doc_embeddings).astype(\"float32\")\n",
        "\n",
        "# Build FAISS index for efficient similarity search\n",
        "index = faiss.IndexFlatL2(embedding_matrix.shape[1])\n",
        "index.add(embedding_matrix)\n",
        "\n",
        "# Function to retrieve the most relevant document\n",
        "def retrieve(query, top_k=1):\n",
        "    query_embedding = model.encode(query)  # Encode the query\n",
        "    query_vector = np.array(query_embedding).astype(\"float32\")\n",
        "\n",
        "    # Search for the closest document in the FAISS index\n",
        "    distances, indices = index.search(np.array([query_vector]), top_k)\n",
        "    return [documents[idx] for idx in indices[0]]\n",
        "\n",
        "# Function to generate response based on retrieved document\n",
        "def generate_response(query):\n",
        "    relevant_docs = retrieve(query)\n",
        "    input_text = f\"{relevant_docs[0]} Context: {query}\"\n",
        "\n",
        "    return input_text  # Simply return the relevant document for demonstration\n",
        "\n",
        "# Test RAG with a sample query\n",
        "query = \"What are some interesting movies from the last year?\"\n",
        "response = generate_response(query)\n",
        "print(\"Generated Response:\", response)"
      ],
      "metadata": {
        "id": "6I3i1Qv7ki5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Flk8kM8K7I7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}